; Copy this file to `.env` and fill in your API keys and settings.
; Uncomment the provider/model lines for the LLM you want to use.
; See below for example configurations for OpenAI, Groq, and Ollama.

; LLM_PROVIDER=openai
; LLM_MODEL=gpt-4o-mini

; LLM_PROVIDER=groq
; LLM_MODEL=llama-3.3-70b-versatile

; LLM_PROVIDER=ollama
; LLM_MODEL=gemma3:4b

LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini

OPENAI_API_KEY=your-openai-api-key-here
GROQ_API_KEY=your-groq-api-key-here
OLLAMA_BASE_URL=http://localhost:11434/v1

PORT=8000
