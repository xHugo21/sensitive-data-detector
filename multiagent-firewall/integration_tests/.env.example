# LLM Provider Configuration for Integration Tests

# The LLM provider to use
LLM_PROVIDER=ollama

# The model to use for LLM detection
LLM_MODEL=gemma3:4b

# Your API key for the LLM provider
LLM_API_KEY=your-api-key-here

# Extra parameters for the LLM. Useful to set temperature to 0 for consistent results.
LLM_EXTRA_PARAMS={"temperature":0, "top_p":1.0, "frequency_penalty":0, "presence_penalty":0, "repeat_penalty":1.0, "top_k":1, "drop_params":true, "response_format":{"type":"json_object"}}

# Force LLM detector to always run even if decision is already 'block'
FORCE_LLM_DETECTOR=false

# OCR Configuration (Optional)
# Tesseract language code (default: eng)
#OCR_LANG=eng

# Minimum confidence threshold 0-100 (default: 0)
#OCR_CONFIDENCE_THRESHOLD=60

# Custom tesseract binary path (optional)
#TESSERACT_CMD=/usr/local/bin/tesseract

# NER Configuration (Optional)
#NER_ENABLED=true
#NER_MODEL=urchade/gliner_multi-v2.1
#NER_MIN_SCORE=0.7
