# LLM Provider Configuration for Integration Tests

# The LLM provider to use
LLM_PROVIDER=ollama

# The model to use for LLM detection
LLM_MODEL=gemma3:4b

# Your API key for the LLM provider
LLM_API_KEY=your-api-key-here

# Extra parameters for the LLM. Useful to set temperature to 0 for consistent results.
LLM_EXTRA_PARAMS={"temperature":0, "top_p":1.0, "frequency_penalty":0, "presence_penalty":0, "repeat_penalty":1.0, "top_k":1, "drop_params":true, "response_format":{"type":"json_object"}}

# Force LLM detector to always run even if decision is already 'block'
FORCE_LLM_DETECTOR=false

# Integration dataset configuration
INTEGRATION_DATASET_LOCALES=us
INTEGRATION_DATASET_MAX_CASES=200
INTEGRATION_DATASET_SEED=1337

# NER Configuration (Optional)
NER_ENABLED=false
NER_MODEL=urchade/gliner_multi-v2.1
NER_MIN_SCORE=0.7
